import torch
import torch.nn.functional as F # Importa la API funcional de torch, incluyendo softmax
import gradio as gr # Gradio para crear interfaces web
from transformers import LlamaForCausalLM
from model import predict_params, AudioDataset # Importaciones personalizadas: carga de modelo y procesamiento de audio
import torchaudio # Librer√≠a para procesamiento de audio
from dotenv import load_dotenv

load_dotenv()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Verifica si hay GPU disponible, de lo contrario usa CPU
model_class, id2label_class = predict_params(
    model_path="distilhubert-finetuned-mixed-data", # Ruta al modelo para la predicci√≥n de clases de llanto
    dataset_path="data/mixed_data", # Ruta al dataset de audio mixto
    filter_white_noise=True, # Indica que se filtrar√° el ruido blanco
    undersample_normal=True # Activa el submuestreo para equilibrar clases
    )
model_mon, id2label_mon = predict_params(
    model_path="distilhubert-finetuned-cry-detector", # Ruta al modelo detector de llanto
    dataset_path="data/baby_cry_detection", # Ruta al dataset de detecci√≥n de llanto
    filter_white_noise=False, # No filtrar ruido blanco en este modelo
    undersample_normal=False # No submuestrear datos
    )

def call(audiopath, model, dataset_path, filter_white_noise, undersample_normal=False):
    model.to(device) # Env√≠a el modelo a la GPU (o CPU si no hay GPU disponible)
    model.eval() # Pone el modelo en modo de evaluaci√≥n (desactiva dropout, batchnorm)
    audio_dataset = AudioDataset(dataset_path, {}, filter_white_noise, undersample_normal) # Carga el dataset de audio con par√°metros espec√≠ficos
    processed_audio = audio_dataset.preprocess_audio(audiopath) # Preprocesa el audio seg√∫n la configuraci√≥n del dataset
    inputs = {"input_values": processed_audio.to(device).unsqueeze(0)} # Prepara los datos para el modelo (env√≠a a GPU y ajusta dimensiones)
    with torch.no_grad(): # Desactiva el c√°lculo del gradiente para ahorrar memoria
        outputs = model(**inputs) # Realiza la inferencia con el modelo
        logits = outputs.logits # Obtiene las predicciones del modelo
    return logits # Retorna los logits (valores sin procesar)

def predict(audio_path_pred):
    with torch.no_grad(): # Desactiva gradientes para la inferencia
        logits = call(audio_path_pred, model=model_class, dataset_path="data/mixed_data", filter_white_noise=True, undersample_normal=False) # Llama a la funci√≥n de inferencia
        predicted_class_ids_class = torch.argmax(logits, dim=-1).item() # Obtiene la clase predicha a partir de los logits
        label_class = id2label_class[predicted_class_ids_class] # Convierte el ID de clase en una etiqueta de texto
        label_mapping = {0: 'Cansancio/Incomodidad', 1: 'Dolor', 2: 'Hambre', 3: 'Problemas para respirar'} # Mapea las etiquetas
        label_class = label_mapping.get(predicted_class_ids_class, label_class) # Si hay una etiqueta personalizada, la usa
    return f"""
        <div style='text-align: center; font-size: 1.5em'>
            <span style='display: inline-block; min-width: 300px;'>{label_class}</span>
        </div>
    """ # Retorna el resultado formateado para mostrar en la interfaz

def predict_stream(audio_path_stream):
    with torch.no_grad(): # Desactiva gradientes durante la inferencia
        logits = call(audio_path_stream, model=model_mon, dataset_path="data/baby_cry_detection", filter_white_noise=False, undersample_normal=False) # Llama al modelo de detecci√≥n de llanto
        probabilities = F.softmax(logits, dim=-1) # Aplica softmax para convertir los logits en probabilidades
        crying_probabilities = probabilities[:, 1] # Obtiene las probabilidades asociadas al llanto
        avg_crying_probability = crying_probabilities.mean()*100 # Calcula la probabilidad promedio de llanto
        if avg_crying_probability < 15: # Si la probabilidad de llanto es menor a un 15%, se predice la raz√≥n
            label_class = predict(audio_path_stream) # Llama a la predicci√≥n para determinar la raz√≥n del llanto
            return f"Est√° llorando por: {label_class}" # Retorna el resultado indicando por qu√© llora
        else:
            return "No est√° llorando" # Si la probabilidad es mayor, indica que no est√° llorando

def decibelios(audio_path_stream):
    waveform, _ = torchaudio.load(audio_path_stream) # Carga el audio y su forma de onda
    rms = torch.sqrt(torch.mean(torch.square(waveform))) # Calcula el valor RMS del audio
    db_level = 20 * torch.log10(rms + 1e-6).item() # Convierte el RMS en decibelios (a√±ade un peque√±o valor para evitar log(0))
    min_db = -80 # Nivel m√≠nimo de decibelios esperado
    max_db = 0 # Nivel m√°ximo de decibelios esperado
    scaled_db_level = (db_level - min_db) / (max_db - min_db) # Escala el nivel de decibelios a un rango entre 0 y 1
    normalized_db_level = scaled_db_level * 100 # Escala el nivel de decibelios a un porcentaje
    return normalized_db_level # Retorna el nivel de decibelios normalizado

def mostrar_decibelios(audio_path_stream, visual_threshold):
    db_level = decibelios(audio_path_stream)# Obtiene el nivel de decibelios del audio
    if db_level > visual_threshold: # Si el nivel de decibelios supera el umbral visual
        status = "Prediciendo..." # Cambia el estado a "Prediciendo"
    else:
        status = "Esperando..." # Si no supera el umbral, indica que est√° "Esperando"
    return f"""
        <div style='text-align: center; font-size: 1.5em'>
            <span>{status}</span>
            <span style='display: inline-block; min-width: 120px;'>Decibelios: {db_level:.2f}</span>
        </div>
    """ # Retorna una cadena HTML con el estado y el nivel de decibelios

def predict_stream_decib(audio_path_stream, visual_threshold):
    db_level = decibelios(audio_path_stream) # Calcula el nivel de decibelios
    if db_level > visual_threshold: # Si supera el umbral, hace una predicci√≥n
        prediction = display_prediction_stream(audio_path_stream) # Llama a la funci√≥n de predicci√≥n
    else:
        prediction = "" # Si no supera el umbral, no muestra predicci√≥n
    return f"""
        <div style='text-align: center; font-size: 1.5em; min-height: 2em;'>
            <span style='display: inline-block; min-width: 300px;'>{prediction}</span>
        </div>
    """ # Retorna el resultado o nada si no supera el umbral

def chatbot_config(message, history: list[tuple[str, str]]):
    system_message = "You are a Chatbot specialized in baby health and care." # Mensaje inicial del chatbot
    max_tokens = 512 # M√°ximo de tokens para la respuesta
    temperature = 0.5 # Controla la aleatoriedad de las respuestas
    top_p = 0.95 # Top-p sampling para filtrar palabras
    messages = [system_message] # Configura el mensaje del sistema para el chatbot
    for val in history: # A√±ade el historial de la conversaci√≥n al mensaje
        if val[0]:
            messages.append(val[0]) # A√±ade los mensajes del usuario
        if val[1]:
            messages.append(val[1]) # A√±ade las respuestas del asistente
    messages.append(message) # A√±ade el mensaje actual del usuario
    full_prompt = "/n".join(messages)
    inputs = tokenizer(full_prompt, return_tensors="pt").input_ids.to(device)
    ouputs = model.generate(
        inputs,
        max_length=max_tokens,
        temperature=temperature,
        top_p=top_p,
        do_sample=True
    )
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response # Retorna la respuesta generada por el modelo

def cambiar_pesta√±a():
    return gr.update(visible=False), gr.update(visible=True) # Esta funci√≥n cambia la visibilidad de las pesta√±as en la interfaz

def display_prediction(audio, prediction_func):
    prediction = prediction_func(audio) # Llama a la funci√≥n de predicci√≥n para obtener el resultado
    return f"<h3 style='text-align: center; font-size: 1.5em;'>{prediction}</h3>" # Retorna el resultado formateado en HTML

def display_prediction_wrapper(audio):
    return display_prediction(audio, predict) # Envuelve la funci√≥n de predicci√≥n "predict" en la funci√≥n "display_prediction"

def display_prediction_stream(audio):
    return display_prediction(audio, predict_stream) # Envuelve la funci√≥n de predicci√≥n "predict_stream" en la funci√≥n "display_prediction"

my_theme = gr.themes.Soft(
    primary_hue="emerald",
    secondary_hue="green",
    neutral_hue="slate",
    text_size="sm",
    spacing_size="sm",
    font=[gr.themes.GoogleFont('Nunito'), 'ui-sans-serif', 'system-ui', 'sans-serif'],
    font_mono=[gr.themes.GoogleFont('Nunito'), 'ui-monospace', 'Consolas', 'monospace'],
    ).set(
    body_background_fill='*neutral_50',
    body_text_color='*neutral_600',
    body_text_size='*text_sm',
    embed_radius='*radius_md',
    shadow_drop='*shadow_spread',
    shadow_spread='*button_shadow_active'
    )

with gr.Blocks(theme=my_theme, fill_height=True, fill_width=True) as demo:
    with gr.Column(visible=True) as inicial:
        gr.HTML(
            """
            <style>
            @import url('https://fonts.googleapis.com/css2?family=Lobster&display=swap');
            @import url('https://fonts.googleapis.com/css2?family=Roboto&display=swap');

            h1 {
                font-family: 'Lobster', cursive;
                font-size: 5em !important;
                text-align: center;
                margin: 0;
            }

            .gr-button {
                background-color: #4CAF50 !important;
                color: white !important;
                border: none;
                padding: 25px 50px;
                text-align: center;
                text-decoration: none;
                display: inline-block;
                font-family: 'Lobster', cursive;
                font-size: 2em !important;
                margin: 4px 2px;
                cursor: pointer;
                border-radius: 12px;
            }

            .gr-button:hover {
                background-color: #45a049;
            }
            h2 {
                font-family: 'Lobster', cursive;
                font-size: 3em !important;
                text-align: center;
                margin: 0;
            }
            p.slogan, h4, p, h3 {
                font-family: 'Roboto', sans-serif;
                text-align: center;
            }
            </style>
            <h1>Iremia</h1>
            <h4 style='text-align: center; font-size: 1.5em'>El mejor aliado para el bienestar de tu beb√©</h4>
            """
        )
        gr.Markdown(
            "<h4 style='text-align: left; font-size: 1.5em;'>¬øQu√© es Iremia?</h4>"
            "<p style='text-align: left'>Iremia es un proyecto llevado a cabo por un grupo de estudiantes interesados en el desarrollo de modelos de inteligencia artificial, enfocados espec√≠ficamente en casos de uso relevantes para ayudar a cuidar a los m√°s peque√±os de la casa.</p>"
            "<h4 style='text-align: left; font-size: 1.5em;'>Nuestra misi√≥n</h4>"
            "<p style='text-align: left'>Sabemos que la paternidad puede suponer un gran desaf√≠o. Nuestra misi√≥n es brindarles a todos los padres unas herramientas de √∫ltima tecnolog√≠a que los ayuden a navegar esos primeros meses de vida tan cruciales en el desarrollo de sus peque√±os.</p>"
            "<h4 style='text-align: left; font-size: 1.5em;'>¬øQu√© ofrece Iremia?</h4>"
            "<p style='text-align: left'>Chatbot: Pregunta a nuestro asistente que te ayudar√° con cualquier duda que tengas sobre el cuidado de tu beb√©.</p>"
            "<p style='text-align: left'>Predictor: Con nuestro modelo de inteligencia artificial somos capaces de predecir por qu√© tu beb√© est√° llorando.</p>"
            "<p style='text-align: left'>Monitor: Nuestro monitor no es como otros que hay en el mercado, ya que es capaz de reconocer si un sonido es un llanto del beb√© o no; y si est√° llorando, predice autom√°ticamente la causa. D√°ndote la tranquilidad de saber siempre qu√© pasa con tu peque√±o, ahorr√°ndote tiempo y horas de sue√±o.</p>"
        )
        boton_inicial = gr.Button("¬°Prueba nuestros modelos!")
    with gr.Column(visible=False) as chatbot: # Columna para la pesta√±a del chatbot
        gr.Markdown("<h2>Asistente</h2>") # T√≠tulo de la pesta√±a del chatbot
        gr.Markdown("<h4 style='text-align: center; font-size: 1.5em'>Pregunta a nuestro asistente cualquier duda que tengas sobre el cuidado de tu beb√©</h4>")  # Descripci√≥n de la pesta√±a del chatbot
        gr.ChatInterface(
            chatbot_config, # Funci√≥n de configuraci√≥n del chatbot
            theme=my_theme, # Tema personalizado para la interfaz
            retry_btn=None, # Bot√≥n de reintentar desactivado
            undo_btn=None, # Bot√≥n de deshacer desactivado
            clear_btn="Limpiar üóëÔ∏è", # Bot√≥n de limpiar mensajes
            submit_btn="Enviar", # Bot√≥n de enviar mensaje
            autofocus=True, # Enfocar autom√°ticamente el campo de entrada de texto
            fill_height=True, # Rellenar el espacio verticalmente
        )
        with gr.Row(): # Fila para los botones de cambio de pesta√±a
            with gr.Column(): # Columna para el bot√≥n del predictor
                gr.Markdown("<h2>Predictor</h2>") # T√≠tulo de la pesta√±a del chatbot
                boton_predictor = gr.Button("Probar predictor") # Bot√≥n para cambiar a la pesta√±a del predictor
            with gr.Column(): # Columna para el bot√≥n del monitor
                gr.Markdown("<h2>Monitor</h2>") # T√≠tulo de la pesta√±a del chatbot
                boton_monitor = gr.Button("Probar monitor") # Bot√≥n para cambiar a la pesta√±a del monitor
        boton_volver_inicio = gr.Button("Volver al inicio") # Bot√≥n para volver a la pesta√±a inicial
    with gr.Column(visible=False) as pag_predictor: # Columna para la pesta√±a del predictor
        gr.Markdown("<h2>Predictor</h2>") # T√≠tulo de la pesta√±a del predictor
        gr.Markdown("<h4 style='text-align: center; font-size: 1.5em'>Descubre por qu√© tu beb√© est√° llorando</h4>") # Descripci√≥n de la pesta√±a del predictor
        audio_input = gr.Audio(
            min_length=1.0, # Duraci√≥n m√≠nima del audio requerida
            format="wav", # Formato de audio admitido
            label="Baby recorder", # Etiqueta del campo de entrada de audio
            type="filepath", # Tipo de entrada de audio (archivo)
        )
        prediction_output = gr.Markdown() # Salida para mostrar la predicci√≥n
        gr.Button("¬øPor qu√© llora?").click(
            display_prediction_wrapper, # Funci√≥n de predicci√≥n para el bot√≥n
            inputs=audio_input, # Entrada de audio para la funci√≥n de predicci√≥n
            outputs=gr.Markdown() # Salida para mostrar la predicci√≥n
        )
        gr.Button("Volver").click(cambiar_pesta√±a, outputs=[pag_predictor, chatbot]) # Bot√≥n para volver a la pesta√±a del chatbot
    with gr.Column(visible=False) as pag_monitor: # Columna para la pesta√±a del monitor
        gr.Markdown("<h2>Monitor</h2>") # T√≠tulo de la pesta√±a del monitor
        gr.Markdown("<h4 style='text-align: center; font-size: 1.5em'>Detecta en tiempo real si tu beb√© est√° llorando y por qu√©</h4>")  # Descripci√≥n de la pesta√±a del monitor
        audio_stream = gr.Audio(
            format="wav", # Formato de audio admitido
            label="Baby recorder", # Etiqueta del campo de entrada de audio
            type="filepath", # Tipo de entrada de audio (archivo)
            streaming=True # Habilitar la transmisi√≥n de audio en tiempo real
        )
        threshold_db = gr.Slider(
            minimum=0, # Valor m√≠nimo del umbral de ruido
            maximum=120, # Valor m√°ximo del umbral de ruido
            step=1, # Paso del umbral de ruido
            value=20, # Valor inicial del umbral de ruido
            label="Umbral de ruido para activar la predicci√≥n:" # Etiqueta del control deslizante del umbral de ruido
        )
        volver = gr.Button("Volver") # Bot√≥n para volver a la pesta√±a del chatbot
        audio_stream.stream(
            mostrar_decibelios, # Funci√≥n para mostrar el nivel de decibelios
            inputs=[audio_stream, threshold_db], # Entradas para la funci√≥n de mostrar decibelios
            outputs=gr.HTML() # Salida para mostrar el nivel de decibelios
        )
        audio_stream.stream(
            predict_stream_decib, # Funci√≥n para realizar la predicci√≥n en tiempo real
            inputs=[audio_stream, threshold_db], # Entradas para la funci√≥n de predicci√≥n en tiempo real
            outputs=gr.HTML() # Salida para mostrar la predicci√≥n en tiempo real
        )
        volver.click(cambiar_pesta√±a, outputs=[pag_monitor, chatbot]) # Bot√≥n para volver a la pesta√±a del chatbot
    boton_inicial.click(cambiar_pesta√±a, outputs=[inicial, chatbot]) # Bot√≥n para cambiar a la pesta√±a inicial
    boton_volver_inicio.click(cambiar_pesta√±a, outputs=[chatbot, inicial]) # Bot√≥n para volver a la pesta√±a inicial desde el chatbot
    boton_predictor.click(cambiar_pesta√±a, outputs=[chatbot, pag_predictor]) # Bot√≥n para cambiar a la pesta√±a del predictor
    boton_monitor.click(cambiar_pesta√±a, outputs=[chatbot, pag_monitor]) # Bot√≥n para cambiar a la pesta√±a del monitor
demo.launch() # Lanzar la interfaz gr√°fica
